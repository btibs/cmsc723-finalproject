\documentclass[12pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{float}
\usepackage{indentfirst}
\usepackage[font={small}]{caption}
\restylefloat{table}

\title{CMSC 723 Final Project\\
Metaphor Generation}
\author{Joshua Bradley, Isaac Julien, \& Elizabeth McNany}
\date{December 16, 2012}

\begin{document}
\maketitle

\begin{abstract}
We discuss a model for metaphor generation, drawing on limited previous work primarily in metaphor identification.  We first use a parser to identify target words for replacement.  Then, a lexical database and conceptual mappings from linguistic theory are used to replace the target word, resulting in a sentence with metaphorical meaning.  Though evaluation of metaphor is ill-defined in the field, averaging human responses of generated metaphors gives roughly 30\% of generated metaphors as being coherent and logical constructs.  As there is little prior work in the field of metaphor \emph{generation}, our results provide a reasonable baseline. We also give suggestions for future work incorporating machine learning methodologies, which we hypothesize would exhibit a noticeable improvement over the baseline.
\end{abstract}

\newpage
\tableofcontents
\newpage

\section{Introduction}

Metaphors have often been thought of as just rhetorical flourish, however when analyzed in a more abstract manner, they are also one of the most powerful elements of language. Of all theories surrounding metaphors, one of the most popularly accepted is the Conceptual Metaphor Theory \cite{lakoff80}. Lakoff and Johnson argue that on a grand scale, all of language is a metaphor to some degree \ldots that our conceptual system (how we perceive reality) is largely metaphorical. Metaphors affect our thoughts and actions, and "structure our perceptions and understanding". Since \cite{lakoff80}, the study of metaphors has become a topic of interest. Throughout NLP, metaphors are known to be a crux of disambiguation, which has motivated research efforts toward metaphor identification. In this paper, we have taken a different approach to studying metaphor. We use the Conceptual Metaphor Theory to construct a model for \emph{generating} metaphors.

\section{Related Work}

A majority of the work done on metaphors thus far falls in one of two areas: conceptual metaphor mapping \cite{lakoff80} \cite{lakoff89}, and identifying metaphors \cite{shutova101} \cite{pragglejaz}.

In 2007, the Pragglejaz Group introduced the ``Metaphor Identification Procedure’’, which has become a seminal procedure due to its ``universal’’ approach for identifying metaphors. Some limitations (admitted by the author) are known to exist with this procedure however, in that it does not account for all types of existing metaphors (for example, metaphorical utterances in conversation) \cite{pragglejaz}. The lack of agreed upon criteria as to what exactly constitutes a metaphor has also become a major issue amongst researchers.

Recently, there has been an attempt at an unsupervised approach to metaphor identification, involving the clustering of verbs and nouns, which resulted in a system having a precision of 0.79 \cite{shutova101}. This approach relies on a small seed set of metaphorical relation mappings, of which unsupervised noun and verb clustering is performed on, in order to harvest potential target domain concepts. Then, a search through a POS-annotated dataset (the British National Corpus in this case) is performed to look for metaphorical expressions describing the target domain concepts. In summary, this approach generates syntactically similarly-structured metaphors. One limitation to this approach is that it only identifies common metaphors. Less general metaphors (i.e. metaphors created by a particular age group, metaphors only understood in specific geographic regions) and metaphors that break syntactic rules would be less likely to be found \cite{gentner01}.

We were able to locate one paper directly related to metaphor generation \cite{jones92}. In this, Jones looks at generating a subclass of metaphors, which he calls transparently-motivated metaphors. Transparently-motivated metaphors are similar to conventional metaphors, however they also include novel/dead metaphors whereas conventional metaphors, by definition, do not. As admitted by the author, the "qualities" he specifies that decide whether or not a domain is a reasonable metaphorical domain do constrain the number of potential domains for a metaphor mapping to occur in. One severe limitation that exist in the approach outlined in \cite{jones92} is that the author relies on the "detailed knowledge" of human experience to decide which candidate metaphors are better when descending the hyponym hierarchy of a domain. No suggestions are made as to how to computationally evaluate candidate metaphors.

\section{Background}

Our system makes use of several components from other research, namely: WordNet, for word definitions and relations; and the Berkeley Parser, for part-of-speech tagging and parsing input sentences.

\subsection{WordNet}

WordNet is a ``large lexical database of English'' \cite{wordnet}. The fundamental unit in WordNet is a synset, a cognitively synonymous group of words. Each synset may include a definition and example sentence, as well as lexical and semantic links to other synsets. These links distinguish WordNet from an ordinary dictionary or thesaurus by identifying relationships between words and concepts other than synonymy.

The primary relation between noun synsets is hypernymy (Figure \ref{fig:wordnettree}). A noun \emph{NOUN1} is a hypernym of some other noun \emph{NOUN2} if \emph{NOUN2} is a type of \emph{NOUN1}. For instance, a \emph{dog} is a type of \emph{canine}, so \emph{canine} is a hypernym of \emph{dog}, and \emph{dog} is a hyponym of \emph{canine}. WordNet nouns form a hypernym tree, with synsets at the top having a more general meaning (``entity''), and synsets lower down in the tree having more specific meaning (``Cardigan Welsh Corgi'').

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{wordnet-tree.png}
	\caption{The WordNet hypernym tree.}
	\label{fig:wordnettree}
\end{figure}

\subsection{Berkeley Parser}
\label{sec:berkeleyparser}

We are using the Berkeley Parser \cite{berkeleyparser} for parsing the input sentences.  The Berkeley Parser uses a probabilistic context-free grammar to generate and find the most likely parse tree for an input sentence or phrase.  A full parse, as opposed to part of speech tagging only, is desirable for the task of metaphor generation so that the structure can be used to find relevant words, especially in sentences with multiple phrases or clauses.  This process is described in greater detail in Section \ref{sec:identtarget}.

In order to efficiently handle the large number of input sentences for testing, we wrote a Python interface to the parser that returns output parses for given phrases or input files.  The parser output is then converted into a parse tree suitable for use in the remainder of processing.

\section{Model}

A conceptual schematic of our metaphor generation model is included as Figure \ref{fig:schematic}.  Our system first parses the input, as described in Section \ref{sec:berkeleyparser}.  Using the resulting parse tree, a target word for metaphorical replacement is identified based on several common grammatical structures of metaphor.  Then, using WordNet and a list of conceptual mappings, a replacement for the target word is found, giving a metaphorical output sentence.  A diagram showing detailed steps for an example sentence is included at the end of this section as Figure \ref{fig:mapoutline}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{schematic.png}
	\caption{Conceptual schematic for metaphor generation, from input sentence to output.}
	\label{fig:schematic}
\end{figure}

\subsection{Identifying Target Word}
\label{sec:identtarget}
In order to identify an appropriate target word to replace with a metaphor, we focused on detecting three basic grammatical structures for metaphors: ``\emph{NOUN} is \emph{NOUN}'', ``\emph{NOUN} \emph{VERB}'', and ``\emph{ADJ} \emph{NOUN}'' or ``\emph{NOUN} is \emph{ADJ}''.  Examples of each type of metaphor are given in Table \ref{tab:metaphorexamples}.

\begin{table}[h]
	\centering
	\small
	\begin{tabular}{|l|c|l|} \hline
		\textbf{Pattern} & \textbf{Metaphor} & \textbf{Example}\\	\hline
		\emph{NOUN1} is \emph{NOUN2} & \emph{NOUN2} & That person is a pig.\\ \hline
		\emph{NOUN} \emph{VERB} & \emph{VERB} & She flew down the stairs.\\ \hline
		\emph{ADJ} \emph{NOUN} or \emph{NOUN} is \emph{ADJ} & \emph{ADJ} & The salesman is slimy.\\ \hline
	\end{tabular}
	\caption{Basic metaphor patterns and examples.}
	\label{tab:metaphorexamples}
\end{table}

We search for these example patterns in the parse from the input sentence, and if successful, return the pattern found and positions of the relevant words.  This information is then passed to the next component of our model to determine appropriate metaphorical substitutions for the words.

\subsection{Conceptual Mapping}

\subsubsection{Candidate Generation}

At this point we have selected a target word in some context to replace. We would like to apply our conceptual mapping from literal to metaphorical domains. This first requires finding a possible conceptual mapping from our target word. To do this, we find a WordNet synset for this word, and then move up the hypernym tree until we either find a synset in the mapping or reach the top of the tree. If we find a synset in the mapping, then we know that the concept expressed by the original word can be expressed metaphorically by one or several other concepts. For each of these mapped-to concepts, we select all of the synsets in the subtree rooted at that concept as candidate replacements (Figures \ref{fig:wnmapping}, \ref{fig:wnmapexample}); in other words, all hyponyms of the concept.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{wordnetmapping.png}
	\caption{Conceptual schematic for finding metaphorical substitutions via WordNet, given a candidate input word.}
	\label{fig:wnmapping}
\end{figure}

This immediately runs into the problem of word sense disambiguation; given a word ``knight'', we must decide if this word means ``a person of noble birth'' or ``a chess piece shaped to resemble the head of a horse''. One option is to select a sense based on frequency, using tag count, a measure of the number of times a particular sense is tagged in a certain corpus. This approach, the most common sense heuristic, is a difficult baseline to beat for WSD \cite{mccarthy}. However, we find it problematic because of inconsistency in the tag counts. Instead, we select all possible synsets sharing the same part of speech as the target word, and assume that when we later evaluate possible replacement words, erroneous senses are more likely to be filtered out.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{wordnet-replacement.png}
	\caption{Example of selecting all candidate replacement words.}
	\label{fig:wnmapexample}
\end{figure}

\subsubsection{Candidate Selection}

We now need to choose one of the possible replacement words from potentially large set of candidates. Each candidate is a synset in WordNet, which includes a gloss (definition) and possibly example sentences. Our approach is to choose the candidate whose gloss and example sentence overlap the most with the context of the target word in its original text.

We explore two approaches. The first is the Jaccard Similarity of the context of the candidate word, which is the set of words in the gloss and example sentences, and the context of the target word, which is the set of words in the same sentence. We remove stop words from the contexts and calculate the Jaccard Similarity. If $C_c$ is the set of words in the context of the candidate word, and $C_t$ is the set of words in the context of the replacement word, this is $(C_c \cap C_t) / (C_c \cup C_t)$.

The second attempts to measure the semantic similarity of words in $C_c$ and $C_t$. Shortest Ancestral Path (SAP) is a measure of semantic similarity based on the intuition that words close together in the WordNet hypernym tree are likely to be closely related. For example, in Figure \ref{fig:wnmapexample}, we would expect ``cat'' to be more closely related to ``dog'' than to ``worker''. We implement a similarity metric between $C_c$ and $C_t$ that considers the average SAP between all pairs of words in $C_c \times C_t$.

Since calculating SAP for all pairs of words is computationally expensive, we first limit the set of candidate words by requiring a Jaccard Similarity above some threshold. However, in the end, both methods give very similar results.

\subsubsection{Adjectives and Verbs}

The method outlined above will work when the target word is a noun. When the target word is an adjective or a verb, we have to do a little more work. WordNet includes a ``derivationally related form'' link which connects lexically related words across parts of speech, such as ``work'' and ``worker''. When the target word is not a noun, we follow this link to a noun, perform the method above with that noun, and finally convert back to the original part of speech by search for derivationally related forms of the best candidate noun with the correct part of speech.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{mappingoutline.png}
	\caption{Schematic of overall sentence processing, from input to output.}
	\label{fig:mapoutline}
\end{figure}

\section{Results}

\subsection{Data}
We evaluated our system on 829 definitions from WordNet synsets. Definitions are ideal for testing because they are of the form:

\begin{center}
    \emph{Account: a record or narrative description of past events.}
\end{center}

From which it is easy to generate a sentence like:

\begin{center}
    \emph{An account is a record or narrative description of past events.}
\end{center}

We can then attempt to replace the second noun in the definition (``account'') with a metaphorical equivalent, using the rest of the definition as context. Our system generates 199 metaphors as outlined above.

\subsection{Evaluation}

As noted in the related work section, people often debate what exactly constitutes a metaphor, and evaluating each output of our system as ``right'' or ``wrong'' is difficult. We include our own evaluation of the output, as well as the evaluation of other human readers.

We find that our system does produce some sentences that include genuine, insightful uses of metaphor. The rest of the sentences range from interesting and strange to absurd and comical. We divide the results into three categories, described in Table \ref{tab:evalcats}.

\begin{table}[h]
	\centering
	\small
	\begin{tabular}{|c|p{12cm}|} \hline
		\textbf{Category} & \textbf{Description}\\ \hline
		1 & Metaphor usage makes sense; one would not be surprised to hear a person use this metaphor\\ \hline
        2 & Metaphor is understandable and possibly interesting but strange; one wouldn’t expect a person to use this metaphor\\ \hline
		3 & Metaphor is absurd, makes no sense\\ \hline
	\end{tabular}
	\caption{Metaphor evaluation categories.}
	\label{tab:evalcats}
\end{table}

Table \ref{tab:results} shows some of the more interesting outputs that fall under each category. The first line of each sample is the original definition, and the second is the definition after a word is replaced with a metaphorical equivalent.

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{|c|p{12cm}|} \hline
		\textbf{Category} & \textbf{Examples}\\ \hline
		1 & 
		A problem is a source of difficulty.\par
        A problem is a headstream of difficulty.\par
        \medskip
        A employee is a worker who is hired to perform a job.\par
        A employee is a machine who is hired to perform a job.\par
        \medskip
        A desire is the feeling that accompanies an unsatisfied state.\par
        A desire is the famishment that accompanies an unsatisfied state.\par
        \\ \hline
        2 & 
        A psychologist is a scientist trained in psychology.\par
        A psychologist is a work animal trained in psychology.\par
        \medskip
        A case is a special set of circumstances.\par
        A case is a special conservatoire of circumstances.\par
        \medskip
        Nationalism is the doctrine that your national culture is superior to any other.\par
        Nationalism is the costume that your national culture is superior to any other.\par
        \\ \hline
		3 & 
		A magnitude is the property of relative size or extent.\par
        A magnitude is the property of relative peanut or extent.\par
        \medskip
        A king is a male sovereign; ruler of a kingdom.\par
        A king is a male female; ruler of a kingdom.\par
        \medskip
        A thought is the organized beliefs of a period or group or individual.\par
        A thought is the organized cat scratch disease of a period or group or individual.\par
        \medskip
        A chemist is a scientist who specializes in chemistry.\par
        A chemist is a rotisserie who specializes in chemistry.\par
		\\ \hline
	\end{tabular}
	\caption{Example original and generated metaphors for each category.}
	\label{tab:results}
\end{table}

In addition to our own evaluation, we also asked four human readers to categorize each of the 199 generated sentences (Table \ref{tab:catresults}).

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|c|c|c|} \hline
    \textbf{Evaluator} & \textbf{Category 1} & \textbf{Category 2} & \textbf{Category 3} \\ \hline
    Us & 18 & 26 & 155\\ \hline
    Reader 1 & 31 & 53 & 115\\ \hline
    Reader 2 & 12 & 19 & 168\\ \hline
    Reader 3 & 15 & 46 & 139\\ \hline
    Reader 4 & 16 & 47 & 137\\ \hline
    \textbf{Average Percent} & \textbf{9.2} & \textbf{19.2} & \textbf{71.6} \\ \hline
    \end{tabular}
    \caption{Evaluation of generated metaphors}
    \label{tab:catresults}
\end{table}

On average, human readers classified 9.2\% of the generated metaphors as Category 1, 19.2\% as Category 2, and 71.6\% as Category 3. Of the 199 new sentences generated, roughly 30\% are coherent uses of metaphor. The remaining 70\% contain metaphors with no clear conceptual connection between the original and replacement word, but are surprisingly entertaining to read.

There is also a good amount of variation between evaluators in assigning examples to categories. This reflects the fact that different people understand metaphor in different ways, making the evaluation of a task like metaphor identification challenging. Metaphor is not a binary attribute of a word or phrase; it may be closer to a scalar property based on abstraction from a concrete or literal definition.

\section{Conclusion and Future Work}

Conclusion-type things go here.

There is clearly room for improvement.  Without changing our fundamental methods, one step is to add additional conceptual metaphors, which would improve the overall number of metaphors generated. We included many from Lakoff et. al. \cite{lakoff89}, but some mappings did not translate well into WordNet definitions and were left out.

When identifying replacement words, we use the first word of the appropriate type for a pattern.  This can produce skewed results: for instance, given the sentence ``The dog ate a bowl of food'', ``bowl'' will be identified as a candidate for metaphorical replacement, though ``food'' might be a better choice.  This would require leveraging the parse information more completely in the target identification stage.

We hypothesize a significant improvement might be realized by more carefully choosing hyponyms when traversing downwards in the tree.  This may be accomplished by using machine learning methods to determine appropriate replacements.
Future Work - Describe the machine learning approach -> goal would be to learn the characteristic that motivates a conceptual mapping.  (xml metaphor corpus)

\newpage
% Bibliography Section
\begin{thebibliography}{9}

\bibitem{ahrens}
  K. Ahrens. 2010.
  Mapping Principles for Conceptual Metaphors.
  \emph{Researching and Applying Metaphor in the Real World}.

\bibitem{gentner01}
  D. Gentner, B. Bowdle. 2001.
  Convention, Form, and Figurative Language Processing.
  \emph{Metaphor and Symbol, 16(3 \& 4), 223-247}.

\bibitem{steen12}
  J. Herrmann, et al.  2012.
  \emph{VU Amsterdam Metaphor Corpus}.
  University of Oxford.

\bibitem{jones92}
  M. Jones. 1992.
  Generating A Specific Class of Metaphors.
  In \emph{Proceedings of the 30th annual meeting on Association for Computational Linguistics (ACL '92)}. Association for Computational Linguistics, Stroudsburg, PA, USA.
 
\bibitem{lakoff89}
  G. Lakoff, J. Espenson, A. Goldberg. 1989.
  \emph{Master Metaphor List}.
  University of California at Berkeley.
  
\bibitem{lakoff80}
  G. Lakoff, M. Johnson. 1980.
  \emph{Metaphors We Live By}.
  University of Chicago Press.

\bibitem{mason04}
  Z. Mason. 2004.
  \emph{CorMet: A Computational, Corpus-Based Conventional Metaphor Extraction System}.
  Brandeis University.

\bibitem{mccarthy}
  D. McCarthy, R. Koeling, J. Weeds, J. Carrol. 2004.
  Using Automatically Acquired Predominant Senses for Word Sense.
  \emph{Proceedings of the ACL SENSEVAL-3 workshop, 2004}.

\bibitem{wordnet}
  G. Miller. 1995.
  WordNet: A Lexical Database for English.
  \emph{Communications of the ACM Vol. 38, No. 11: 39-41}.

\bibitem{berkeleyparser}
  S. Petrov, L. Barrett, R. Thibaux, D. Klein. 2006.
  Learning Accurate, Compact, and Interpretable Tree Annotation.
  In \emph{Proceedings of COLING-ACL, 2006}.

\bibitem{pragglejaz}
  Pragglejaz Group. 2007.
  MIP: A Method for Identifying Metaphorically Used Words in Discourse.
  \emph{Metaphor and Symbol, 22(1), I-39}.

\bibitem{shutova101}
  E. Shutova, L. Sun, and A. Korhonen, 2010.
  Metaphor Identification Using Verb and Noun Clustering.
  In \emph{Proceedings of COLING 2010}.
  Beijing, China.
  
\bibitem{shutova102}
  E. Shutova. 2010.
  Models of Metaphor in NLP,
  In \emph{Proceedings of ACL 2010}.
  Uppsala, Sweden.

\end{thebibliography}

\end{document}
